# Transformer-Models
Medical Question Answering with Transformer Models
This report outlines the development and evaluation of a BERT-based Question Answering (QA) model using the MedQuAD (Medical Question Answering Dataset). Leveraging advanced NLP techniques, our goal was to enable accurate and contextually relevant responses to medical inquiries.
The process begins with library installation and data preprocessing, including text cleaning and aggregation by question type. Following dataset curation, model configuration, and train-test splitting are performed. The BERT-based QA architecture is initialized, and rigorous training ensues, iteratively refining model parameters.
Evaluation metrics such as accuracy, precision, recall, BLEU score, and ROUGE scores are employed to assess model performance. Through this report, we elucidate the process of developing and evaluating a BERT-based QA model, aiming to enhance NLP capabilities in the medical domain.
